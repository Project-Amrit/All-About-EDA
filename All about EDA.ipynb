{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "980d99a2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "## 1. Types of Exploratory Data Analysis:\n",
    "\n",
    "- 1.1 Univariate Analysis:\n",
    "\n",
    "- 1.2 Bivariate Analysis:\n",
    "\n",
    "- 1.3 Multivariate Analysis:\n",
    "\n",
    "- 1.4 Continuous and Categorical Variables Analysis:\n",
    "\n",
    "    **(1.4) Key Concepts:**\n",
    "    - Distinguishing Variable Types: Continuous (Quantitative) vs. Categorical (Qualitative).\n",
    "    - Visualization Techniques: Different plots for each variable type.\n",
    "\n",
    "    **(1.4) Key Points:**\n",
    "    - Recognizing the nature of variables and selecting appropriate visualizations.\n",
    "    - Tailoring analysis based on variable types.\n",
    "\n",
    "## 2. Steps of Exploratory Data Analysis:\n",
    "\n",
    "### 2.1 Data Collection:\n",
    "\n",
    "**Key Points:**\n",
    "- Gathering data from diverse sources, ensuring completeness and accuracy.\n",
    "\n",
    "\n",
    "### 2.2 Data Cleaning:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Handling Missing Data: Imputation or removal.\n",
    "- Duplicate Removal: Ensuring unique observations.\n",
    "- Error Correction: Identifying and fixing inconsistencies.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 2.2.1. Identifying Missing Values:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "```\n",
    "\n",
    "#### 2.2.2. Imputation:\n",
    "```python\n",
    "# Replace missing values with the mean\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Replace missing values in a specific column with the median\n",
    "df['column_name'].fillna(df['column_name'].median(), inplace=True)\n",
    "```\n",
    "\n",
    "#### 2.2.3. Deletion:\n",
    "```python\n",
    "# Remove rows with any missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove columns with any missing values\n",
    "df.dropna(axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "#### 2.2.4. Interpolation:\n",
    "```python\n",
    "# Linear interpolation for missing values\n",
    "df.interpolate(method='linear', inplace=True)\n",
    "```\n",
    "\n",
    "#### 2.2.5. Predictive Modeling:\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'target_column' is the column with missing values\n",
    "train_data = df.dropna(subset=['target_column'])\n",
    "test_data = df[df['target_column'].isnull()]\n",
    "\n",
    "X = train_data.drop('target_column', axis=1)\n",
    "y = train_data['target_column']\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict missing values\n",
    "predicted_values = model.predict(test_data.drop('target_column', axis=1))\n",
    "\n",
    "# Fill missing values with predictions\n",
    "df.loc[df['target_column'].isnull(), 'target_column'] = predicted_values\n",
    "```\n",
    "\n",
    "#### 2.2.6. Create Missingness Indicator:\n",
    "```python\n",
    "# Add a binary column indicating missing values in 'column_name'\n",
    "df['column_name_missing'] = df['column_name'].isnull().astype(int)\n",
    "```\n",
    "\n",
    "These are basic examples, and you should adapt them based on your specific dataset and requirements. Always consider the context and nature of your data when choosing a method.\n",
    "\n",
    "\n",
    "**Key Points:**\n",
    "- Creating a clean, reliable dataset for analysis.\n",
    "\n",
    "### 2.3 Descriptive Statistics:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Central Tendency Measures: Mean, Median, Mode.\n",
    "- Variability Measures: Range, Variance, Standard Deviation.\n",
    "\n",
    "\n",
    "Descriptive statistics help summarize and describe the main features of a dataset. Here are some codes in Python using the pandas library for basic descriptive statistics in Exploratory Data Analysis (EDA):\n",
    "\n",
    "#### 2.3.1. Summary Statistics:\n",
    "```python\n",
    "# Display basic summary statistics for numerical columns\n",
    "summary_stats = df.describe()\n",
    "print(summary_stats)\n",
    "```\n",
    "\n",
    "#### 2.3.2. Mean, Median, Mode:\n",
    "```python\n",
    "# Mean of a column\n",
    "mean_value = df['numerical_column'].mean()\n",
    "\n",
    "# Median of a column\n",
    "median_value = df['numerical_column'].median()\n",
    "\n",
    "# Mode of a column\n",
    "mode_value = df['categorical_column'].mode()[0]\n",
    "\n",
    "print(f\"Mean: {mean_value}\")\n",
    "print(f\"Median: {median_value}\")\n",
    "print(f\"Mode: {mode_value}\")\n",
    "```\n",
    "\n",
    "#### 2.3.3. Variance and Standard Deviation:\n",
    "```python\n",
    "# Variance of a column\n",
    "variance_value = df['numerical_column'].var()\n",
    "\n",
    "# Standard deviation of a column\n",
    "std_deviation_value = df['numerical_column'].std()\n",
    "\n",
    "print(f\"Variance: {variance_value}\")\n",
    "print(f\"Standard Deviation: {std_deviation_value}\")\n",
    "```\n",
    "\n",
    "#### 2.3.4. Skewness and Kurtosis:\n",
    "```python\n",
    "# Skewness of a column\n",
    "skewness_value = df['numerical_column'].skew()\n",
    "\n",
    "# Kurtosis of a column\n",
    "kurtosis_value = df['numerical_column'].kurt()\n",
    "\n",
    "print(f\"Skewness: {skewness_value}\")\n",
    "print(f\"Kurtosis: {kurtosis_value}\")\n",
    "```\n",
    "\n",
    "#### 2.3.5. Count of Unique Values:\n",
    "```python\n",
    "# Count of unique values in a column\n",
    "unique_values_count = df['categorical_column'].nunique()\n",
    "\n",
    "print(f\"Number of unique values: {unique_values_count}\")\n",
    "```\n",
    "\n",
    "These codes provide a basic overview of descriptive statistics that you can use to understand the characteristics of your dataset. Depending on your data, you may want to explore additional statistics and visualizations to gain deeper insights.\n",
    "\n",
    "\n",
    "**Key Points:**\n",
    "- Summarizing and understanding the basic statistical properties of the data.\n",
    "\n",
    "### 2.4 Univariate Analysis:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Histograms: Visualizing the distribution of a single variable.\n",
    "- Box Plots: Identifying outliers and understanding quartiles.\n",
    "\n",
    "Univariate analysis focuses on analyzing a single variable at a time to understand its distribution and characteristics. Here are some codes in Python using the pandas and matplotlib/seaborn libraries for univariate analysis in Exploratory Data Analysis (EDA):\n",
    "\n",
    "#### 2.4.1. Histogram:\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a histogram for a numerical column\n",
    "plt.hist(df['numerical_column'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Numerical Column')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.4.2. Box Plot:\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a box plot for a numerical column\n",
    "sns.boxplot(x=df['categorical_column'], y=df['numerical_column'])\n",
    "plt.title('Box Plot of Numerical Column by Category')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.4.3. Count Plot (Bar Plot for Categorical Variables):\n",
    "```python\n",
    "# Plot a count plot for a categorical column\n",
    "sns.countplot(x='categorical_column', data=df, palette='Set3')\n",
    "plt.title('Count Plot of Categorical Column')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.4.4. Kernel Density Estimate (KDE) Plot:\n",
    "```python\n",
    "# Plot a KDE plot for a numerical column\n",
    "sns.kdeplot(df['numerical_column'], fill=True, color='skyblue')\n",
    "plt.title('Kernel Density Estimate (KDE) Plot')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Density')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.4.5. Pie Chart (for small categorical variables):\n",
    "```python\n",
    "# Plot a pie chart for a categorical column\n",
    "plt.pie(df['categorical_column'].value_counts(), labels=df['categorical_column'].unique(), autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Pie Chart of Categorical Column')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "These are basic examples of univariate analysis. Depending on your dataset and the type of variable you are analyzing, you may want to explore other visualizations and summary statistics to gain a deeper understanding of the distribution and characteristics of individual variables.\n",
    "\n",
    "**Key Points:**\n",
    "- Revealing patterns and characteristics of individual variables.\n",
    "\n",
    "### 2.5 Bivariate Analysis:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Correlation Coefficient: Quantifying the strength and direction of a relationship.\n",
    "- Scatter Plots: Visualizing relationships between two variables.\n",
    "\n",
    "Bivariate analysis involves exploring the relationship between two variables. Here are some codes in Python using the pandas, matplotlib, and seaborn libraries for bivariate analysis in Exploratory Data Analysis (EDA):\n",
    "\n",
    "#### 2.5.1. Scatter Plot:\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot for two numerical columns\n",
    "plt.scatter(df['numerical_column_1'], df['numerical_column_2'], alpha=0.5)\n",
    "plt.title('Scatter Plot of Numerical Column 1 vs Numerical Column 2')\n",
    "plt.xlabel('Numerical Column 1')\n",
    "plt.ylabel('Numerical Column 2')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.5.2. Line Plot:\n",
    "```python\n",
    "# Create a line plot for two numerical columns\n",
    "plt.plot(df['numerical_column_1'], df['numerical_column_2'])\n",
    "plt.title('Line Plot of Numerical Column 1 vs Numerical Column 2')\n",
    "plt.xlabel('Numerical Column 1')\n",
    "plt.ylabel('Numerical Column 2')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.5.3. Heatmap (Correlation Matrix):\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Plot a heatmap of the correlation matrix\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.5.4. Pair Plot:\n",
    "```python\n",
    "# Create a pair plot for multiple numerical columns\n",
    "sns.pairplot(df[['numerical_column_1', 'numerical_column_2', 'numerical_column_3']])\n",
    "plt.suptitle('Pair Plot of Numerical Columns', y=1.02)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.5.5. Box Plot:\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a box plot for a numerical column grouped by a categorical column\n",
    "sns.boxplot(x=df['categorical_column'], y=df['numerical_column'])\n",
    "plt.title('Box Plot of Numerical Column by Category')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### 2.5.6. Violin Plot:\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a violin plot for a numerical column grouped by a categorical column\n",
    "sns.violinplot(x=df['categorical_column'], y=df['numerical_column'])\n",
    "plt.title('Violin Plot of Numerical Column by Category')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "These examples demonstrate various ways to explore the relationship between two variables in your dataset. Customize the visualizations based on your specific needs and the nature of your data.\n",
    "\n",
    "\n",
    "**Key Points:**\n",
    "- Identifying associations between pairs of variables.\n",
    "\n",
    "### 2.6 Multivariate Analysis:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Heatmaps: Visualizing correlations among multiple variables.\n",
    "- Pair Plots: Understanding joint distributions.\n",
    "\n",
    "Multivariate analysis involves examining relationships among three or more variables simultaneously. Here are some codes in Python using the pandas, matplotlib, and seaborn libraries for multivariate analysis in Exploratory Data Analysis (EDA):\n",
    "\n",
    "### 1. Pair Plot with Hue (Color by a Categorical Variable):\n",
    "```python\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a pair plot with hue for a categorical column\n",
    "sns.pairplot(df, hue='categorical_column', palette='Set1')\n",
    "plt.suptitle('Pair Plot with Hue', y=1.02)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 2. 3D Scatter Plot:\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a 3D scatter plot for three numerical columns\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(df['numerical_column_1'], df['numerical_column_2'], df['numerical_column_3'], c='skyblue', s=50)\n",
    "ax.set_xlabel('Numerical Column 1')\n",
    "ax.set_ylabel('Numerical Column 2')\n",
    "ax.set_zlabel('Numerical Column 3')\n",
    "plt.title('3D Scatter Plot of Numerical Columns')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 3. Parallel Coordinates Plot:\n",
    "```python\n",
    "from pandas.plotting import parallel_coordinates\n",
    "\n",
    "# Create a parallel coordinates plot for selected columns\n",
    "selected_columns = ['numerical_column_1', 'numerical_column_2', 'numerical_column_3', 'categorical_column']\n",
    "parallel_coordinates(df[selected_columns], 'categorical_column', colormap='viridis')\n",
    "plt.title('Parallel Coordinates Plot')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 4. Bubble Chart:\n",
    "```python\n",
    "# Create a bubble chart with three numerical columns and size representing a fourth numerical column\n",
    "plt.scatter(df['numerical_column_1'], df['numerical_column_2'], s=df['numerical_column_3']*10, c='skyblue', alpha=0.5)\n",
    "plt.title('Bubble Chart of Numerical Columns')\n",
    "plt.xlabel('Numerical Column 1')\n",
    "plt.ylabel('Numerical Column 2')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 5. 3D Surface Plot:\n",
    "```python\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a 3D surface plot for three numerical columns\n",
    "fig = px.scatter_3d(df, x='numerical_column_1', y='numerical_column_2', z='numerical_column_3', color='categorical_column')\n",
    "fig.update_layout(scene=dict(zaxis=dict(range=[df['numerical_column_3'].min(), df['numerical_column_3'].max()])))\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "These codes provide examples of multivariate analysis using various visualization techniques. Customize them based on your specific dataset and analysis goals. Note that some visualizations, such as 3D plots, may require additional libraries like `plotly` for interactive plots.\n",
    "\n",
    "\n",
    "**Key Points:**\n",
    "- Investigating interactions and dependencies among multiple variables.\n",
    "\n",
    "### 2.7 Feature Engineering:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Creating New Features: Enhancing predictive power.\n",
    "- Handling Categorical Variables: Encoding or creating dummy variables.\n",
    "\n",
    "Feature engineering involves creating new features or transforming existing ones to improve the performance of machine learning models. Here are some common feature engineering techniques with example codes in Python using the pandas library:\n",
    "\n",
    "### 1. Handling Missing Values:\n",
    "```python\n",
    "# Filling missing values with the mean of a numerical column\n",
    "df['numerical_column'].fillna(df['numerical_column'].mean(), inplace=True)\n",
    "\n",
    "# Filling missing values in a categorical column with the mode\n",
    "df['categorical_column'].fillna(df['categorical_column'].mode()[0], inplace=True)\n",
    "```\n",
    "\n",
    "### 2. Creating Dummy Variables (One-Hot Encoding):\n",
    "```python\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "df = pd.get_dummies(df, columns=['categorical_column'], drop_first=True)\n",
    "```\n",
    "\n",
    "### 3. Binning (Discretization):\n",
    "```python\n",
    "# Create bins for a numerical column\n",
    "bins = [0, 25, 50, 75, 100]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "df['binned_column'] = pd.cut(df['numerical_column'], bins=bins, labels=labels, include_lowest=True)\n",
    "```\n",
    "\n",
    "### 4. Feature Scaling (Standardization or Min-Max Scaling):\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "df[['numerical_column_1', 'numerical_column_2']] = scaler.fit_transform(df[['numerical_column_1', 'numerical_column_2']])\n",
    "\n",
    "# Min-Max Scaling\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df['numerical_column'] = minmax_scaler.fit_transform(df[['numerical_column']])\n",
    "```\n",
    "\n",
    "### 5. Log Transformation:\n",
    "```python\n",
    "# Apply log transformation to a numerical column\n",
    "df['log_transformed_column'] = np.log1p(df['numerical_column'])\n",
    "```\n",
    "\n",
    "### 6. Creating Interaction Terms:\n",
    "```python\n",
    "# Create an interaction term between two numerical columns\n",
    "df['interaction_term'] = df['numerical_column_1'] * df['numerical_column_2']\n",
    "```\n",
    "\n",
    "### 7. Feature Extraction (Principal Component Analysis - PCA):\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to reduce dimensionality\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df[['numerical_column_1', 'numerical_column_2']])\n",
    "df['pca_component_1'] = pca_result[:, 0]\n",
    "df['pca_component_2'] = pca_result[:, 1]\n",
    "```\n",
    "\n",
    "### 8. Time-Based Features:\n",
    "```python\n",
    "# Extract time-based features from a datetime column\n",
    "df['year'] = df['datetime_column'].dt.year\n",
    "df['month'] = df['datetime_column'].dt.month\n",
    "df['day'] = df['datetime_column'].dt.day\n",
    "df['weekday'] = df['datetime_column'].dt.weekday\n",
    "```\n",
    "\n",
    "These are just a few examples of feature engineering techniques. The specific techniques you choose will depend on the nature of your data and the goals of your machine learning task. Always validate the impact of feature engineering on your model's performance through careful evaluation.\n",
    "\n",
    "\n",
    "**Key Points:**\n",
    "- Improving the dataset for better predictive modeling.\n",
    "\n",
    "### 2.8 Outlier Detection:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Identifying Outliers: Using statistical measures or visualization techniques.\n",
    "\n",
    "Outliers are data points that significantly differ from the majority of the data. Detecting and handling outliers is crucial in data preprocessing. Here are some common techniques for outlier detection with example codes in Python:\n",
    "\n",
    "### 1. Z-Score Method:\n",
    "```python\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate the z-scores for a numerical column\n",
    "z_scores = stats.zscore(df['numerical_column'])\n",
    "\n",
    "# Set a threshold for considering data points as outliers (e.g., z-score > 3 or < -3)\n",
    "threshold = 3\n",
    "outliers = (np.abs(z_scores) > threshold)\n",
    "\n",
    "# Identify and print outlier values\n",
    "outlier_values = df['numerical_column'][outliers]\n",
    "print(\"Outliers:\", outlier_values)\n",
    "```\n",
    "\n",
    "### 2. IQR (Interquartile Range) Method:\n",
    "```python\n",
    "# Calculate the IQR for a numerical column\n",
    "Q1 = df['numerical_column'].quantile(0.25)\n",
    "Q3 = df['numerical_column'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Set a threshold for considering data points as outliers (e.g., Q1 - 1.5 * IQR or Q3 + 1.5 * IQR)\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify and print outlier values\n",
    "outliers = ((df['numerical_column'] < lower_bound) | (df['numerical_column'] > upper_bound))\n",
    "outlier_values = df['numerical_column'][outliers]\n",
    "print(\"Outliers:\", outlier_values)\n",
    "```\n",
    "\n",
    "### 3. Isolation Forest:\n",
    "```python\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Fit Isolation Forest to a numerical column\n",
    "isolation_forest = IsolationForest(contamination=0.05)\n",
    "df['outlier_flag'] = isolation_forest.fit_predict(df[['numerical_column']])\n",
    "\n",
    "# Identify and print outlier values\n",
    "outliers = df[df['outlier_flag'] == -1]['numerical_column']\n",
    "print(\"Outliers:\", outliers)\n",
    "```\n",
    "\n",
    "### 4. Visualizing Box Plots:\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a box plot to visualize potential outliers\n",
    "sns.boxplot(x=df['numerical_column'])\n",
    "plt.title('Box Plot of Numerical Column')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "### 5. Visualizing Scatter Plots:\n",
    "```python\n",
    "# Create a scatter plot to visualize potential outliers\n",
    "plt.scatter(df['numerical_column'], df['another_numerical_column'])\n",
    "plt.title('Scatter Plot of Numerical Columns')\n",
    "plt.xlabel('Numerical Column 1')\n",
    "plt.ylabel('Numerical Column 2')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Choose the method that best fits your data distribution and characteristics. Additionally, always examine and validate the impact of outlier removal on your analysis or machine learning models.\n",
    "\n",
    "**Key Points:**\n",
    "- Ensuring the robustness of analysis by handling outliers appropriately.\n",
    "\n",
    "### 2.9 Visualization and Interpretation:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Effective Visualization Techniques: Choosing the right plots for the right purpose.\n",
    "- Interpretation Skills: Deriving meaningful insights from visualizations.\n",
    "\n",
    "**Key Points:**\n",
    "- Communicating findings through compelling visualizations.\n",
    "- Forming hypotheses and guiding further analysis.\n",
    "\n",
    "### 2.10 Report Findings:\n",
    "\n",
    "**Key Concepts:**\n",
    "- Effective Communication: Summarizing key observations and insights.\n",
    "- Stakeholder Engagement: Making findings accessible and understandable.\n",
    "\n",
    "**Key Points:**\n",
    "- Concluding the EDA process with a clear and concise report.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
